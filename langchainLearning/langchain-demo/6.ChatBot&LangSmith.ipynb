{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7cff09660c9048",
   "metadata": {},
   "source": [
    "## ğŸ“Š LangSmithåŠŸèƒ½\n",
    "\n",
    "ä½¿ç”¨ LangChain æ„å»ºçš„è®¸å¤šåº”ç”¨ç¨‹åºå°†åŒ…å«å¤šä¸ªæ­¥éª¤å’Œå¤šä¸ª LLM è°ƒç”¨çš„è°ƒç”¨ã€‚\n",
    "\n",
    "éšç€è¿™äº›åº”ç”¨ç¨‹åºå˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œèƒ½å¤Ÿæ£€æŸ¥é“¾æˆ–ä»£ç†å†…éƒ¨åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆå˜å¾—è‡³å…³é‡è¦\n",
    "https://smith.langchain.com/\n",
    "\n",
    "1. **ğŸ“ˆ æ€§èƒ½ç›‘æ§**: è¿½è¸ªæ¯æ¬¡ LLM è°ƒç”¨çš„å»¶è¿Ÿã€token ä½¿ç”¨é‡ã€æˆæœ¬ç­‰\n",
    "2. **ğŸ” è°ƒè¯•å·¥å…·**: æŸ¥çœ‹å®Œæ•´çš„è¾“å…¥è¾“å‡ºé“¾è·¯ï¼Œä¾¿äºè°ƒè¯•å¤æ‚çš„ LangChain åº”ç”¨\n",
    "3. **ğŸ“ æ—¥å¿—è®°å½•**: è‡ªåŠ¨è®°å½•æ‰€æœ‰ LLM äº¤äº’ï¼ŒåŒ…æ‹¬ promptã€å“åº”ã€å…ƒæ•°æ®ç­‰\n",
    "4. **ğŸ·ï¸ æ ‡ç­¾ç®¡ç†**: é€šè¿‡é¡¹ç›®ã€ä¼šè¯ã€æ ‡ç­¾ç­‰ç»´åº¦ç»„ç»‡å’Œç­›é€‰è¿½è¸ªæ•°æ®\n",
    "5. **ğŸ“Š æ•°æ®åˆ†æ**: æä¾›ä¸°å¯Œçš„å›¾è¡¨å’Œç»Ÿè®¡ä¿¡æ¯ï¼Œå¸®åŠ©ä¼˜åŒ–åº”ç”¨æ€§èƒ½\n",
    "\n",
    "| ç¯å¢ƒå˜é‡ | è¯´æ˜ | ç¤ºä¾‹å€¼ |\n",
    "|---------|------|--------|\n",
    "| `LANGSMITH_TRACING` | å¯ç”¨/ç¦ç”¨è¿½è¸ª | `\"true\"` æˆ– `\"false\"` |\n",
    "| `LANGSMITH_API_KEY` | LangSmith API å¯†é’¥ | `\"lsv2_pt_...\"` |\n",
    "| `LANGSMITH_PROJECT` | é¡¹ç›®åç§° | `\"LangChain-Chatbot-20241018\"` |\n",
    "| `LANGSMITH_SESSION` | ä¼šè¯æ ‡è¯† | `\"chatbot-session-1\"` |\n",
    "| `LANGSMITH_TAGS` | æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼‰ | `\"chatbot,demo,glm-4.6\"` |\n",
    "| `LANGSMITH_ENDPOINT` | API ç«¯ç‚¹ | `\"https://api.smith.langchain.com\"` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d3165b6b8b9ba5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T03:00:41.590521Z",
     "start_time": "2025-10-18T03:00:41.582522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š LangSmith è¿½è¸ªå·²å¯ç”¨\n",
      "ğŸ·ï¸ é¡¹ç›®åç§°: LangChain-Chatbot-202510181726\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ğŸ”§ LangSmith é…ç½® - ç”¨äºè¿½è¸ªå’Œç›‘æ§ LLM è°ƒç”¨\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"  # å¯ç”¨è¿½è¸ª\n",
    "\n",
    "# LANGSMITH_API_KEY å·²é…ç½®\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = \"@@@\"\n",
    "\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = f\"LangChain-Chatbot-{datetime.now().strftime('%Y%m%d%H%M')}\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "print(f\"ğŸ“Š LangSmith è¿½è¸ªå·²å¯ç”¨\")\n",
    "print(f\"ğŸ·ï¸ é¡¹ç›®åç§°: {os.environ['LANGSMITH_PROJECT']}\")\n",
    "\n",
    "# åˆå§‹åŒ– LLM æ¨¡å‹\n",
    "# è¿™é‡Œç”¨çš„æ™ºè°±çš„API Key\n",
    "llm_model = ChatOpenAI(\n",
    "    model=\"glm-4.6\",\n",
    "    temperature=0.7,\n",
    "    openai_api_key=os.getenv(\"ZAI_API_KEY\"), \n",
    "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\",\n",
    "    max_tokens=2000,  # æœ€å¤§è¾“å‡º token æ•°\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828797d48d3c24e",
   "metadata": {},
   "source": [
    "## ğŸ” å¯¹æ¯”`langchain_core.messages`å’Œ`langchain.schema`çš„HumanMessage\n",
    "\n",
    "| æ¯”è¾ƒé¡¹   | `langchain_core.messages.HumanMessage`             | `langchain.schema.HumanMessage`             |\n",
    "| -------- | -------------------------------------------------- | ------------------------------------------- |\n",
    "| æ‰€å±æ¨¡å— | `langchain-core`ï¼ˆç‹¬ç«‹æ ¸å¿ƒåº“ï¼‰                     | `langchain` ä¸»åŒ…çš„æ—§ç‰ˆ schema               |\n",
    "| è®¾è®¡ç›®çš„ | æ–°ç‰ˆæ¶ˆæ¯åè®®ï¼ˆå’Œ OpenAI API å¯¹é½ï¼‰                 | æ—§ç‰ˆæ¶ˆæ¯æ ¼å¼å®šä¹‰                            |\n",
    "| ç‰ˆæœ¬æ”¯æŒ | âœ… LangChain â‰¥ 0.1ï¼ˆæ¨èï¼‰                          | âš ï¸ æ—§ç‰ˆå…¼å®¹å±‚ï¼Œæœªæ¥å¯èƒ½ç§»é™¤                  |\n",
    "| åº•å±‚ç±»å‹ | `BaseMessage`ï¼ˆæ–°å®šä¹‰ï¼‰                            | `BaseMessage`ï¼ˆæ—§å®šä¹‰ï¼‰                     |\n",
    "| ä½¿ç”¨åœºæ™¯ | ReAct Agentã€LCELã€Runnableã€Tool ç­‰æ–°ç‰ˆæ¥å£       | æ—§å¼ Chainï¼ˆå¦‚ `ConversationChain`ï¼‰        |\n",
    "| å¯¼å…¥ç¤ºä¾‹ | `from langchain_core.messages import HumanMessage` | `from langchain.schema import HumanMessage` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72bd62b00698c41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T03:01:59.933526Z",
     "start_time": "2025-10-18T03:00:41.623523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\nHail and well met!\\n\\nYou have summoned a Knight. I am at your service.\\n\\nMy virtual armor is polished, and I am ready for any quest you have in mind. How may I assist you today?\\n\\nPerhaps you wish to:\\n*   **Learn** about the history of medieval knights and their code of chivalry.\\n*   **Hear a tale** of a famous knight from legend or fiction.\\n*   **Discuss** the strategy of the knight piece in chess.\\n*   Or simply have a **loyal companion** to chat with.\\n\\nJust state your command, and I shall endeavor to help.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1531, 'prompt_tokens': 10, 'total_tokens': 1541, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'glm-4.6', 'system_fingerprint': None, 'id': '20251018172612e8f853261b3a4c92', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--f837b363-c96f-4182-bdcf-1d6013e20e3d-0', usage_metadata={'input_tokens': 10, 'output_tokens': 1531, 'total_tokens': 1541, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.schema import HumanMessage\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm_model.invoke([\n",
    "    HumanMessage(content=\"Hi! Knight\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chatbot_intro",
   "metadata": {},
   "source": [
    "## ğŸ¤– å¸¦æœ‰ LangSmith è¿½è¸ªçš„èŠå¤©æœºå™¨äººå®ç°\n",
    "\n",
    "ä¸‹é¢æˆ‘ä»¬å°†å®ç°ä¸€ä¸ªå®Œæ•´çš„èŠå¤©æœºå™¨äººï¼Œå¹¶å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LangSmith è¿½è¸ªå…¶è¿è¡Œæƒ…å†µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "chatbot_implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– èŠå¤©æœºå™¨äººå·²åˆå§‹åŒ–å®Œæˆï¼\n",
      "ğŸ“Š æ‰€æœ‰å¯¹è¯éƒ½å°†è¢« LangSmith è‡ªåŠ¨è¿½è¸ª\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "import uuid\n",
    "from typing import Dict\n",
    "\n",
    "# ğŸ“ åˆ›å»ºèŠå¤©æç¤ºæ¨¡æ¿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„ AI åŠ©æ‰‹ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š\n",
    "1. ç”¨ç®€æ´ã€æ¸…æ™°çš„è¯­è¨€å›ç­”é—®é¢˜\n",
    "2. å¦‚æœä¸ç¡®å®šç­”æ¡ˆï¼Œè¯·è¯šå®åœ°è¯´æ˜\n",
    "3. ä¿æŒå¯¹è¯çš„è¿è´¯æ€§å’Œä¸Šä¸‹æ–‡ç†è§£\n",
    "4. é€‚å½“ä½¿ç”¨ emoji è®©å¯¹è¯æ›´ç”ŸåŠ¨\n",
    "\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# å­˜å‚¨ä¸åŒä¼šè¯çš„èŠå¤©å†å²\n",
    "store: Dict[str, BaseChatMessageHistory] = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"è·å–æˆ–åˆ›å»ºä¼šè¯å†å²\"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# åˆ›å»ºå¸¦æœ‰å†å²è®°å½•çš„èŠå¤©é“¾\n",
    "chain = prompt | llm_model\n",
    "\n",
    "# åŒ…è£…é“¾ä»¥æ”¯æŒæ¶ˆæ¯å†å²\n",
    "chatbot = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "print(\"ğŸ¤– èŠå¤©æœºå™¨äººå·²åˆå§‹åŒ–å®Œæˆï¼\")\n",
    "print(\"ğŸ“Š æ‰€æœ‰å¯¹è¯éƒ½å°†è¢« LangSmith è‡ªåŠ¨è¿½è¸ª\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a028c6",
   "metadata": {},
   "source": [
    "### ğŸ¯ æµ‹è¯•èŠå¤©æœºå™¨äºº - å•è½®å¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "test_single_conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ†” ä¼šè¯ ID: 33899279-6380-4abe-a99f-64eca36ab681\n",
      "ğŸ‘¤ ç”¨æˆ·: ä½ å¥½ï¼æˆ‘æƒ³äº†è§£ä¸€ä¸‹ LangChain çš„åŸºæœ¬æ¦‚å¿µã€‚\n",
      "ğŸ¤– åŠ©æ‰‹: \n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ ä»‹ç» LangChain çš„åŸºæœ¬æ¦‚å¿µã€‚ğŸ‘‹\n",
      "\n",
      "ç®€å•æ¥è¯´ï¼Œ**LangChain æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶ï¼Œä¸“é—¨ç”¨æ¥æ„å»ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨ç¨‹åºã€‚**\n",
      "\n",
      "ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªâ€œç‘å£«å†›åˆ€â€ ğŸ› ï¸ï¼Œå®ƒæä¾›äº†å„ç§å·¥å…·ï¼Œè®©ä½ èƒ½è½»æ¾åœ°å°† LLMï¼ˆå¦‚ GPT-4ï¼‰ä¸å…¶ä»–æ•°æ®æºæˆ–åŠŸèƒ½è¿æ¥èµ·æ¥ï¼Œä»è€Œå®ç°æ›´å¤æ‚ã€æ›´å¼ºå¤§çš„ä»»åŠ¡ã€‚\n",
      "\n",
      "ä¸‹é¢æ˜¯ LangChain çš„å‡ ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼Œæˆ‘ä¼šç”¨æœ€ç®€å•çš„æ–¹å¼ä¸ºä½ è§£...\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_id = str(uuid.uuid4())  # ç”Ÿæˆå”¯ä¸€ä¼šè¯ ID\n",
    "print(f\"ğŸ†” ä¼šè¯ ID: {session_id}\")\n",
    "\n",
    "# ç¬¬ä¸€è½®å¯¹è¯\n",
    "response1 = chatbot.invoke(\n",
    "    {\"input\": \"ä½ å¥½ï¼æˆ‘æƒ³äº†è§£ä¸€ä¸‹ LangChain çš„åŸºæœ¬æ¦‚å¿µã€‚\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "\n",
    "print(\"ğŸ‘¤ ç”¨æˆ·:\", \"ä½ å¥½ï¼æˆ‘æƒ³äº†è§£ä¸€ä¸‹ LangChain çš„åŸºæœ¬æ¦‚å¿µã€‚\")\n",
    "print(\"ğŸ¤– åŠ©æ‰‹:\", response1.content[:200] + \"...\" if len(response1.content) > 200 else response1.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a0291f",
   "metadata": {},
   "source": [
    "### ğŸ”„ æµ‹è¯•èŠå¤©æœºå™¨äºº - å¤šè½®å¯¹è¯ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "test_multi_conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ ç”¨æˆ·: èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹ Chain çš„æ¦‚å¿µå—ï¼Ÿ\n",
      "ğŸ¤– åŠ©æ‰‹: \n",
      "å½“ç„¶å¯ä»¥ï¼æˆ‘ä»¬æ¥æ·±å…¥èŠèŠ **Chain (é“¾)** è¿™ä¸ªæ ¸å¿ƒæ¦‚å¿µã€‚ğŸ§\n",
      "\n",
      "å¦‚æœè¯´ LangChain æ˜¯ä¸€ä¸ªâ€œç‘å£«å†›åˆ€â€ï¼Œé‚£ä¹ˆ **Chain å°±æ˜¯ä½¿ç”¨è¿™äº›å·¥å…·çš„â€œæ ‡å‡†æ“ä½œæµç¨‹â€**ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Chain çš„æ ¸å¿ƒæ€æƒ³ï¼šä¸²è”ä¸ç»„åˆ\n",
      "\n",
      "æƒ³è±¡ä¸€ä¸‹å·¥å‚é‡Œçš„æµæ°´çº¿ ğŸ­ï¼š\n",
      "*   åŸææ–™ï¼ˆæ¯”å¦‚ç”¨æˆ·çš„è¾“å…¥ï¼‰è¿›å…¥æµæ°´çº¿ã€‚\n",
      "*   ç»è¿‡ç¬¬ä¸€ä¸ªå·¥ä½ï¼ˆæ¯”å¦‚ **æç¤ºæ¨¡æ¿**ï¼‰ï¼Œè¢«å¡‘é€ æˆç‰¹å®šçš„æ ¼å¼ã€‚\n",
      "...\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ‘¤ ç”¨æˆ·: ç»™æˆ‘ä¸€ä¸ªç®€å•çš„ä»£ç ç¤ºä¾‹å§\n",
      "ğŸ¤– åŠ©æ‰‹: \n",
      "æ²¡é—®é¢˜ï¼æˆ‘ä»¬æ¥å†™ä¸€ä¸ªæœ€ç®€å•ã€æœ€ç»å…¸çš„â€œHello Worldâ€çº§åˆ«çš„ä¾‹å­ï¼š**ä¸€ä¸ªç®€å•çš„ç¿»è¯‘é“¾**ã€‚ğŸ‘\n",
      "\n",
      "è¿™ä¸ªä¾‹å­ä¼šæŠŠä½ è¾“å…¥çš„ä»»ä½•ä¸­æ–‡å¥å­ï¼Œç¿»è¯‘æˆè‹±æ–‡ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ç¬¬ 1 æ­¥ï¼šç¯å¢ƒå‡†å¤‡\n",
      "\n",
      "åœ¨è¿è¡Œä»£ç å‰ï¼Œè¯·ç¡®ä¿ä½ å·²ç»å®‰è£…äº†å¿…è¦çš„åº“å¹¶è®¾ç½®äº† API å¯†é’¥ã€‚\n",
      "\n",
      "```bash\n",
      "# å®‰è£… LangChain å’Œ OpenAI çš„åŒ…\n",
      "pip install langchain langchain...\n"
     ]
    }
   ],
   "source": [
    "response2 = chatbot.invoke(\n",
    "    {\"input\": \"èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹ Chain çš„æ¦‚å¿µå—ï¼Ÿ\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "\n",
    "print(\"ğŸ‘¤ ç”¨æˆ·:\", \"èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹ Chain çš„æ¦‚å¿µå—ï¼Ÿ\")\n",
    "print(\"ğŸ¤– åŠ©æ‰‹:\", response2.content[:200] + \"...\" if len(response2.content) > 200 else response2.content)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ç¬¬ä¸‰è½®å¯¹è¯\n",
    "response3 = chatbot.invoke(\n",
    "    {\"input\": \"ç»™æˆ‘ä¸€ä¸ªç®€å•çš„ä»£ç ç¤ºä¾‹å§\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "\n",
    "print(\"ğŸ‘¤ ç”¨æˆ·:\", \"ç»™æˆ‘ä¸€ä¸ªç®€å•çš„ä»£ç ç¤ºä¾‹å§\")\n",
    "print(\"ğŸ¤– åŠ©æ‰‹:\", response3.content[:200] + \"...\" if len(response3.content) > 200 else response3.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc2b92",
   "metadata": {},
   "source": [
    "### ğŸ“Š æŸ¥çœ‹å½“å‰ä¼šè¯çš„èŠå¤©å†å²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "view_chat_history",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ å½“å‰ä¼šè¯å…±æœ‰ 6 æ¡æ¶ˆæ¯ï¼š\n",
      "\n",
      "1. ğŸ‘¤ ç”¨æˆ·: ä½ å¥½ï¼æˆ‘æƒ³äº†è§£ä¸€ä¸‹ LangChain çš„åŸºæœ¬æ¦‚å¿µã€‚\n",
      "\n",
      "2. ğŸ¤– åŠ©æ‰‹: \n",
      "ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ ä»‹ç» LangChain çš„åŸºæœ¬æ¦‚å¿µã€‚ğŸ‘‹\n",
      "\n",
      "ç®€å•æ¥è¯´ï¼Œ**LangChain æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶ï¼Œä¸“é—¨ç”¨æ¥æ„å»ºåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨ç¨‹åºã€‚**\n",
      "\n",
      "ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªâ€œç‘å£«å†›...\n",
      "\n",
      "3. ğŸ‘¤ ç”¨æˆ·: èƒ½è¯¦ç»†è§£é‡Šä¸€ä¸‹ Chain çš„æ¦‚å¿µå—ï¼Ÿ\n",
      "\n",
      "4. ğŸ¤– åŠ©æ‰‹: \n",
      "å½“ç„¶å¯ä»¥ï¼æˆ‘ä»¬æ¥æ·±å…¥èŠèŠ **Chain (é“¾)** è¿™ä¸ªæ ¸å¿ƒæ¦‚å¿µã€‚ğŸ§\n",
      "\n",
      "å¦‚æœè¯´ LangChain æ˜¯ä¸€ä¸ªâ€œç‘å£«å†›åˆ€â€ï¼Œé‚£ä¹ˆ **Chain å°±æ˜¯ä½¿ç”¨è¿™äº›å·¥å…·çš„â€œæ ‡å‡†æ“ä½œæµç¨‹â€**ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "...\n",
      "\n",
      "5. ğŸ‘¤ ç”¨æˆ·: ç»™æˆ‘ä¸€ä¸ªç®€å•çš„ä»£ç ç¤ºä¾‹å§\n",
      "\n",
      "6. ğŸ¤– åŠ©æ‰‹: \n",
      "æ²¡é—®é¢˜ï¼æˆ‘ä»¬æ¥å†™ä¸€ä¸ªæœ€ç®€å•ã€æœ€ç»å…¸çš„â€œHello Worldâ€çº§åˆ«çš„ä¾‹å­ï¼š**ä¸€ä¸ªç®€å•çš„ç¿»è¯‘é“¾**ã€‚ğŸ‘\n",
      "\n",
      "è¿™ä¸ªä¾‹å­ä¼šæŠŠä½ è¾“å…¥çš„ä»»ä½•ä¸­æ–‡å¥å­ï¼Œç¿»è¯‘æˆè‹±æ–‡ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ç¬¬ 1 æ­¥ï¼šç¯å¢ƒå‡†å¤‡\n",
      "\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = get_session_history(session_id)\n",
    "print(f\"ğŸ“ å½“å‰ä¼šè¯å…±æœ‰ {len(history.messages)} æ¡æ¶ˆæ¯ï¼š\\n\")\n",
    "\n",
    "for i, message in enumerate(history.messages, 1):\n",
    "    role = \"ğŸ‘¤ ç”¨æˆ·\" if isinstance(message, HumanMessage) else \"ğŸ¤– åŠ©æ‰‹\"\n",
    "    content = message.content[:100] + \"...\" if len(message.content) > 100 else message.content\n",
    "    print(f\"{i}. {role}: {content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa3044",
   "metadata": {},
   "source": [
    "### ğŸ¯ é«˜çº§åŠŸèƒ½ï¼šå¸¦æ ‡ç­¾çš„è¿½è¸ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advanced_tracing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ·ï¸ å¸¦æ ‡ç­¾çš„è¿½è¸ªå·²å®Œæˆ\n",
      "ğŸ“ å“åº”: \n",
      "æ‚¨å¥½ï¼å¾ˆæŠ±æ­‰æ‚¨å¯¹è´­ä¹°çš„å•†å“ä¸æ»¡æ„ã€‚é€€è´§æµç¨‹é€šå¸¸ä¼šæ ¹æ®æ‚¨è´­ä¹°å•†å“çš„å¹³å°æˆ–å•†å®¶æœ‰æ‰€ä¸åŒï¼Œä½†å¤§ä½“ä¸Šå¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\n",
      "\n",
      "ğŸ“¦ **é€šç”¨é€€è´§æµç¨‹**\n",
      "\n",
      "1.  **æŸ¥çœ‹é€€è´§æ”¿ç­–**ï¼šé¦–å…ˆï¼Œè¯·åœ¨æ‚¨çš„è®¢å•è¯¦æƒ…é¡µæˆ–å•†å“é¡µé¢æŸ¥çœ‹å•†å®¶çš„é€€è´§æ”¿ç­–ã€‚é‡ç‚¹å…³æ³¨é€€è´§æ—¶é—´ï¼ˆå¦‚7å¤©æ— ç†ç”±ï¼‰ã€å•†å“çŠ¶æ€è¦æ±‚ï¼ˆå¦‚æœªæ‹†å°ã€ä¸å½±å“äºŒæ¬¡...\n",
      "\n",
      "ğŸ’¡ åœ¨ LangSmith ä¸­å¯ä»¥é€šè¿‡ 'customer_service' æ ‡ç­¾ç­›é€‰æ­¤ç±»å¯¹è¯\n"
     ]
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(\n",
    "    name=\"æ™ºèƒ½å®¢æœå¯¹è¯\",\n",
    "    tags=[\"customer_service\", \"glm-4.6\", \"production\"]\n",
    ")\n",
    "def customer_service_chat(user_input: str, session_id: str) -> str:\n",
    "    \"\"\"å®¢æœèŠå¤©åŠŸèƒ½ï¼Œå¸¦æœ‰è‡ªå®šä¹‰è¿½è¸ª\"\"\"\n",
    "    response = chatbot.invoke(\n",
    "        {\"input\": user_input},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    return response.content\n",
    "\n",
    "# æµ‹è¯•å¸¦æ ‡ç­¾çš„è¿½è¸ª\n",
    "customer_session = str(uuid.uuid4())\n",
    "result = customer_service_chat(\n",
    "    \"æˆ‘æƒ³é€€è´§ï¼Œè¯·é—®æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ\", \n",
    "    customer_session\n",
    ")\n",
    "\n",
    "print(\"ğŸ·ï¸ å¸¦æ ‡ç­¾çš„è¿½è¸ªå·²å®Œæˆ\")\n",
    "print(f\"ğŸ“ å“åº”: {result[:150]}...\" if len(result) > 150 else result)\n",
    "print(\"\\nğŸ’¡ åœ¨ LangSmith ä¸­å¯ä»¥é€šè¿‡ 'customer_service' æ ‡ç­¾ç­›é€‰æ­¤ç±»å¯¹è¯\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
